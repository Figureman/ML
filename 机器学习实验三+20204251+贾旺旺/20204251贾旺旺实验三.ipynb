{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e341de-b74f-4dcb-9416-cda6ca23d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bfb541-4dff-43d7-912b-24b4d5709f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attr_name2split_value=None, attr_value=None, parent=None, left_child=None, right_child=None,\n",
    "                 leaf_type=None, remain_attrs=None, data_indexes=None):\n",
    "        \"\"\"\n",
    "        节点类初始化函数\n",
    "        节点类别标识：\n",
    "                    分支节点：attr_name2split_value != {} and leaf_type == None\n",
    "                    叶子节点：attr_name2split_value == {} and leaf_type != None\n",
    "                    判断叶子节点优先使用leaf_type，防止忘记更新attr_name2split_value导致出错\n",
    "        param attr_value: 本节点中样本的属性值，与父节点的属性名相对应。\n",
    "        param attr_name2split_value: 本节点进行划分子节点的属性名与值的字典 {name:value}\n",
    "        param parent: 本节点的父节点\n",
    "        param left_child: 本节点的左孩子\n",
    "        param right_child: 本节点的右孩子\n",
    "        param leaf_type: 本节点若是叶节点，该值标识样本类型\n",
    "        param remain_attrs: 剩余未划分的属性\n",
    "        param data_indexes: 划分到本节点的样本数据下标列表\n",
    "        \"\"\"\n",
    "        self.attr_value = attr_value\n",
    "        self.attr_name2split_value = {} if attr_name2split_value is None else attr_name2split_value\n",
    "        self.parent = parent\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.leaf_type = leaf_type\n",
    "        self.remain_attrs = [] if remain_attrs is None else remain_attrs\n",
    "        self.data_indexes = [] if data_indexes is None else data_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19d0816-81b1-466f-ae8f-c19cbdaac4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self, data_set=None, discrete_attrs=None, tree_type=1, min_samples_leaf=2, max_deepth=9):\n",
    "        \"\"\"\n",
    "        CART类的初始化函数，可以生成分类树与回归树（默认生成分类树）\n",
    "        \n",
    "        param data_set: 训练集的字典列表，以{属性:值}的形式存储，样本类别为最后一个键值对\n",
    "        param discrete_attrs: 离散属性集合\n",
    "        param tree_type: 构造树的类型 1为分类树，0为回归树\n",
    "        param min_samples_leaf: 叶子节点的最小样本量，默认为2\n",
    "        param max_deepth: 递归深度（树的深度），默认位9\n",
    "        return: 得到一颗树的根节点\n",
    "        \"\"\"\n",
    "        self.root = Node()\n",
    "        self.data_set = {} if data_set is None else data_set\n",
    "        self.attr_names = list(data_set[0].keys())[0:-1]\n",
    "        self.discrete_attrs = [] if discrete_attrs is None else discrete_attrs\n",
    "        self.tree_type = tree_type\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_deepth = max_deepth\n",
    "        if tree_type == 1:\n",
    "            self.grow_classify_CART()\n",
    "        else:\n",
    "            self.grow_regression_CART()\n",
    "\n",
    "\n",
    "    def Gini(self, data_set_v):\n",
    "        \"\"\"\n",
    "        计算输入数据集的基尼值\n",
    "        \n",
    "        param data_set_v: 输入数据集的字典列表，每一个样本对应一个dict，存储{属性:值}，所有样本组成一个list\n",
    "        return: 基尼值\n",
    "        \"\"\"\n",
    "        data_num = len(data_set_v)\n",
    "        # 统计每个类别的数量\n",
    "        type_cnt_dict = {} \n",
    "        for item in data_set_v:\n",
    "            type_cnt_dict[item['target']] = \\\n",
    "                            type_cnt_dict.get(item['target'], 0) + 1\n",
    "        # 基于公式4.5计算基尼值\n",
    "        P_k_sum = 0\n",
    "        for key in type_cnt_dict.keys():\n",
    "            P_k_sum += pow(type_cnt_dict[key] / data_num, 2)\n",
    "        gini_value = 1 - P_k_sum\n",
    "        return gini_value\n",
    "\n",
    "\n",
    "    def Gini_index(self, data_set, divide_attr):\n",
    "        \"\"\"\n",
    "        计算输入属性的基尼指数\n",
    "        \n",
    "        param data_set: 当前节点数据集的字典列表 [{'sepal_length':7.7}, {'sepal_width':6.8}...{'target':1}]\n",
    "        param divide_attr: 当前用于划分数据集的属性\n",
    "        return: 输入属性的基尼指数与最优划分点\n",
    "        \"\"\"\n",
    "        data_num = len(data_set)\n",
    "        gini_index_value = 0 # 最终返回的基尼指数\n",
    "\n",
    "        '''\n",
    "        由于data_set是数据集的字典列表，首先要得到分割属性a对应的数据列表v_list\n",
    "        遍历data_set，添加每一项a对应的值到v_list\n",
    "        求出候选划分点集合\n",
    "        对每个候选划分点t，求比t大的数据集和比t小的数据集\n",
    "        对这两个数据集分别求基尼值，用公式4.6求解得到一个候选划分点的基尼指数\n",
    "        对比所有候选划分点的基尼指数，选择最小的一个作为属性a的基尼指数\n",
    "        类比离散的，连续的里面每个候选划分点分割开的2个数据集的地位和离散中的属性a对应的4个属性值求出的4个数据集地位相同\n",
    "        而每个候选划分点相当于属性a的副本，最优的那个点的地位和属性a相同\n",
    "        '''\n",
    "        divide_attr_value_list = [] # 存储划分属性的值\n",
    "        split_points = [] # 存储候选划分点\n",
    "        split_res = [] # 存储候选划分结果\n",
    "        # 统计划分属性的值\n",
    "        for item in data_set:\n",
    "            divide_attr_value_list.append(item[divide_attr])\n",
    "        # 对划分属性的值进行排序\n",
    "        sorted_attr_list = divide_attr_value_list.copy()\n",
    "        sorted_attr_list.sort()\n",
    "        # 统计候选划分点集合\n",
    "        for i in range(data_num-1):\n",
    "            split_points.append((sorted_attr_list[i]+sorted_attr_list[i+1])/2)\n",
    "        \n",
    "        s_split_points = set(split_points)\n",
    "        # 求每个候选划分结果\n",
    "        for point in s_split_points:\n",
    "            data_set_v1 = list(filter(lambda item: item[divide_attr]<=point, data_set))\n",
    "            data_set_v2 = list(filter(lambda item: item[divide_attr]>point, data_set))\n",
    "            gini_index_value1 = (self.Gini(data_set_v1) * len(data_set_v1)) / data_num\n",
    "            gini_index_value2 = (self.Gini(data_set_v2) * len(data_set_v2)) / data_num\n",
    "            split_res.append(gini_index_value1 + gini_index_value2)\n",
    "        # 求最优划分点与对应的基尼指数\n",
    "        gini_index_value = min(split_res)\n",
    "        split_value = split_points[split_res.index(gini_index_value)]\n",
    "        return gini_index_value, split_value\n",
    "\n",
    "\n",
    "    def get_best_divide_attr_classify(self, curr_node):\n",
    "        \"\"\"\n",
    "        基于基尼指数从剩余属性中选择最优划分属性\n",
    "        \n",
    "        param curr_node: 当前节点\n",
    "        return: 返回选择的划分属性与对应的划分值\n",
    "        \"\"\"\n",
    "        attrs_gini_dict = {} # 统计每个属性的基尼指数\n",
    "        attrs_split_value = {} # 统计每个属性的划分值\n",
    "        remain_attrs = curr_node.remain_attrs # 从当前节点中得到剩余属性\n",
    "        # 遍历每个剩余属性，求得基尼指数字典与划分值字典\n",
    "        for attr in remain_attrs:\n",
    "            data_set_a = self.split_data(curr_node.data_indexes)\n",
    "            gini_value_a, split_value_a = self.Gini_index(data_set_a, attr)\n",
    "            attrs_gini_dict[attr] = gini_value_a\n",
    "            attrs_split_value[attr] = split_value_a\n",
    "        # 选择基尼指数最小（优）的划分属性\n",
    "        selected_attr = min(attrs_gini_dict, key=attrs_gini_dict.get)\n",
    "        # 得到该划分属性对应的划分值\n",
    "        split_value = attrs_split_value[selected_attr]\n",
    "        return selected_attr, split_value\n",
    "\n",
    "\n",
    "    def split_data(self, data_indexes):\n",
    "        \"\"\"\n",
    "        辅助函数，按照样本索引列表从原数据集中摘出样本集\n",
    "        \n",
    "        param data_indexes: 某个节点拥有的样本索引列表\n",
    "        return: 该样本索引列表对应的样本集\n",
    "        \"\"\"\n",
    "        data_set = []\n",
    "        for index in data_indexes:\n",
    "            data_set.append(self.data_set[index])\n",
    "        return data_set\n",
    "\n",
    "\n",
    "    def build_classify_tree(self, curr_node, parent_leaf_type=0, deepth=1):\n",
    "        \"\"\"\n",
    "        递归构造分类树算法\n",
    "        \n",
    "        param curr_node: 当前节点\n",
    "        param parent_leaf_type: 父节点样本中最多的类别\n",
    "        param deepth: 当前递归深度\n",
    "        return: 最终构造一颗分类树\n",
    "        \"\"\"\n",
    "        '''\n",
    "        递归算法\n",
    "        判断当前节点拥有的数据是否都是同一类别c，是则标记node为c类叶节点，然后就return\n",
    "        判断待划分属性值是否空，或者是否当前数据属性值全都一样无法区分\n",
    "            是则标记node为数据中最多的类别c，然后就return\n",
    "        选择属性进行划分\n",
    "        为选择的属性生成左孩子和右孩子\n",
    "            如果某个孩子拥有的样本为空，那么就把父亲样本中最多的那个类别标记给该孩子node（因为实在没有数据，没办法继续判断了，只好将父样本中最多的类别当成孩子的类别）\n",
    "            如果不为空，那么就调用build_tree递归\n",
    "        '''\n",
    "        # 得到当前节点的训练集\n",
    "        data_indexes = curr_node.data_indexes\n",
    "        # 判断当前节点样本集是否为空\n",
    "        if len(data_indexes) == 0:\n",
    "            curr_node.leaf_type = parent_leaf_type # 空则标记该孩子节点为父节点中最多的类别（叶节点）\n",
    "            return\n",
    "        node_data_set = self.split_data(data_indexes)\n",
    "        # 得到当前训练集样本对应的类别\n",
    "        node_data_set_targets = []\n",
    "        for item in node_data_set:\n",
    "            node_data_set_targets.append(item['target'])\n",
    "        # 得到当前训练集样本最多的类别\n",
    "        leaf_type = max(node_data_set_targets, key=node_data_set_targets.count)\n",
    "        # 控制递归深度\n",
    "        if deepth >= self.max_deepth:\n",
    "            curr_node.leaf_type = leaf_type\n",
    "            return\n",
    "        # 判断当前节点拥有的样本是否都是同一类别\n",
    "        if len(set(node_data_set_targets)) == 1: \n",
    "            curr_node.leaf_type = node_data_set_targets[0] # 是则标记当前节点为该类别（叶节点）\n",
    "            return\n",
    "\n",
    "        # 判断待划分属性是否为空or样本属性值都一样（类别可能不一样）\n",
    "        remain_attrs = copy.deepcopy(curr_node.remain_attrs) # 得到当前节点的剩余待划分属性\n",
    "        # 判断待划分属性是否为空\n",
    "        empty_flag = 0\n",
    "        if len(remain_attrs) == 0:\n",
    "            empty_flag = 1\n",
    "        # 判断样本属性值是否都一样\n",
    "        temp_node_data_set = copy.deepcopy(node_data_set) # 先复制一份数据\n",
    "        for item in temp_node_data_set:\n",
    "            del item['target'] # 因为类别可能不一样，就先删除类别的键值对\n",
    "        temp_item = temp_node_data_set[0] # 便于比较\n",
    "        same_flag = 1\n",
    "        for item in temp_node_data_set:\n",
    "            if item != temp_item: # 只要有一个不同，数据集中的样本就不一样\n",
    "                same_flag = 0\n",
    "        # 是则标记当前节点为最多样本的类别（叶节点）\n",
    "        if empty_flag or same_flag:\n",
    "            curr_node.leaf_type = leaf_type \n",
    "            return\n",
    "\n",
    "        # 选择最优划分属性\n",
    "        selected_attr, split_value = self.get_best_divide_attr_classify(curr_node)\n",
    "        # 若被选择属性是离散属性，那么本次用完就移除\n",
    "        if selected_attr in self.discrete_attrs:\n",
    "            # 从剩余属性列表中移除被选择的属性\n",
    "            remain_attrs.remove(selected_attr)\n",
    "        # print(selected_attr)\n",
    "        # 填充{划分属性:划分属性值}\n",
    "        curr_node.attr_name2split_value[selected_attr] = split_value\n",
    "\n",
    "        # 为选择的属性生成左孩子和右孩子\n",
    "        # filter函数得到比划分值小、比划分值大的两部分数据集\n",
    "        left_data_set_indexes = list(filter(lambda index: self.data_set[index][selected_attr] <= curr_node.attr_name2split_value[selected_attr], data_indexes))\n",
    "        right_data_set_indexes = list(filter(lambda index: self.data_set[index][selected_attr] > curr_node.attr_name2split_value[selected_attr], data_indexes))\n",
    "        # 左右孩子所划到的样本的属性值，左孩子的属性值为'<=划分值'\n",
    "        left_attr_value = '<=' + str(curr_node.attr_name2split_value[selected_attr])\n",
    "        right_attr_value = '>' + str(curr_node.attr_name2split_value[selected_attr])\n",
    "        curr_node.left_child = Node(attr_value=left_attr_value, parent=curr_node, remain_attrs=remain_attrs, data_indexes=left_data_set_indexes)\n",
    "        curr_node.right_child = Node(attr_value=right_attr_value, parent=curr_node, remain_attrs=remain_attrs, data_indexes=right_data_set_indexes)\n",
    "\n",
    "        # 递归构建左右子树，同时深度+1，并且传参当前节点样本中最多的类别进入子节点的递归\n",
    "        self.build_classify_tree(curr_node.left_child, leaf_type, deepth+1)\n",
    "        self.build_classify_tree(curr_node.right_child, leaf_type, deepth+1)\n",
    "\n",
    "\n",
    "    def grow_classify_CART(self):\n",
    "        \"\"\"\n",
    "        生成一颗分类树\n",
    "        \n",
    "        return: 最终得到一颗分类树，可以沿着根节点走完整棵树\n",
    "        \"\"\"\n",
    "        # 为数据集样本添加下标\n",
    "        root_data_indexes = []\n",
    "        for i in range(len(self.data_set)):\n",
    "            root_data_indexes.append(i)\n",
    "        # 初始化根节点\n",
    "        root_node = Node(remain_attrs=copy.deepcopy(self.attr_names), data_indexes=root_data_indexes)\n",
    "        self.root = root_node\n",
    "        self.build_classify_tree(root_node, parent_leaf_type=0, deepth=1)\n",
    "\n",
    "\n",
    "    def cal_mse(self, data_set_v):\n",
    "        \"\"\"\n",
    "        计算输入数据集的mse\n",
    "        param data_set_v: 输入数据集的字典列表，每一个样本对应一个dict，存储{属性:值}，所有样本组成一个list\n",
    "        return: mse\n",
    "        \"\"\"\n",
    "        data_num = len(data_set_v)\n",
    "        # 统计每个类别的数量\n",
    "        true_scores = []\n",
    "        for item in data_set_v:\n",
    "            true_scores.append(item['target'])\n",
    "        mean_score = sum(true_scores) / data_num\n",
    "        pred_scores = [mean_score] * data_num\n",
    "        # 计算mse\n",
    "        mse = mean_squared_error(true_scores, pred_scores) # 调用sklearn的MSE计算函数\n",
    "        return mse\n",
    "\n",
    "\n",
    "    def get_best_split_point(self, data_set, divide_attr):\n",
    "        \"\"\"\n",
    "        计算输入属性的mse\n",
    "        param data_set: 当前节点数据集的字典列表 [{'sepal_length':7.7}, {'sepal_width':6.8}...{'target':1}]\n",
    "        param divide_attr: 当前用于划分数据集的属性\n",
    "        return: 输入属性的mse与最优划分点\n",
    "        \"\"\"\n",
    "        data_num = len(data_set)\n",
    "        mse_value = 0 # 最终返回的mse\n",
    "\n",
    "        divide_attr_value_list = [] # 存储划分属性的值\n",
    "        split_points = [] # 存储候选划分点\n",
    "        split_res = [] # 存储候选划分结果\n",
    "        # 统计划分属性的值\n",
    "        for item in data_set:\n",
    "            divide_attr_value_list.append(item[divide_attr])\n",
    "        # 对划分属性的值进行排序\n",
    "        sorted_attr_list = divide_attr_value_list.copy()\n",
    "        sorted_attr_list.sort()\n",
    "        # 统计候选划分点集合\n",
    "        for i in range(data_num-1):\n",
    "            split_points.append((sorted_attr_list[i]+sorted_attr_list[i+1])/2)\n",
    "        \n",
    "        s_split_points = set(split_points)\n",
    "        # 求每个候选划分结果\n",
    "        for point in s_split_points:\n",
    "            data_set_v1 = list(filter(lambda item: item[divide_attr]<=point, data_set))\n",
    "            data_set_v2 = list(filter(lambda item: item[divide_attr]>point, data_set))\n",
    "            mse_value1 = (self.Gini(data_set_v1) * len(data_set_v1)) / data_num\n",
    "            mse_value2 = (self.Gini(data_set_v2) * len(data_set_v2)) / data_num\n",
    "            split_res.append(mse_value1 + mse_value2)\n",
    "        # 求最优划分点与对应的mse\n",
    "        mse_value = min(split_res)\n",
    "        split_value = split_points[split_res.index(mse_value)]\n",
    "        return mse_value, split_value\n",
    "\n",
    "\n",
    "    def get_best_divide_attr_reg(self, curr_node):\n",
    "        \"\"\"\n",
    "        基于MSE从剩余属性中选择最优划分属性\n",
    "        param curr_node: 当前节点\n",
    "        return: 返回选择的划分属性与对应的划分值\n",
    "        \"\"\"\n",
    "        attrs_mse_dict = {} # 统计每个属性的mse\n",
    "        attrs_split_value = {} # 统计每个属性的划分值\n",
    "        remain_attrs = curr_node.remain_attrs # 从当前节点中得到剩余属性\n",
    "        # 遍历每个剩余属性，求得mse字典与划分值字典\n",
    "        for attr in remain_attrs:\n",
    "            data_set_a = self.split_data(curr_node.data_indexes)\n",
    "            mse_value_a, split_value_a = self.get_best_split_point(data_set_a, attr)\n",
    "            attrs_mse_dict[attr] = mse_value_a\n",
    "            attrs_split_value[attr] = split_value_a\n",
    "        # 选择mse最小（优）的划分属性\n",
    "        selected_attr = min(attrs_mse_dict, key=attrs_mse_dict.get)\n",
    "        # 得到该划分属性对应的划分值\n",
    "        split_value = attrs_split_value[selected_attr]\n",
    "        return selected_attr, split_value\n",
    "\n",
    "\n",
    "    def build_regression_tree(self, curr_node, parent_mean_score, deepth):\n",
    "        \"\"\"\n",
    "        递归构造回归树算法\n",
    "        \n",
    "        param curr_node: 当前节点\n",
    "        param parent_mean_score: 父节点样本的均值\n",
    "        param deepth: 当前递归深度\n",
    "        return: 最终构造一颗回归树\n",
    "        \"\"\"\n",
    "        '''\n",
    "        每个叶节点的leaf_type现在存储预测值，也就是score\n",
    "        这个分数是该节点样本或者父节点样本的socore均值\n",
    "        递归时，先先选择最优划分属性，然后划分、接下来再递归子节点\n",
    "        最优划分属性选择：\n",
    "            先计算每个属性，每个划分点的均方差\n",
    "            选最小均方差的属性\n",
    "        '''\n",
    "        # 得到当前节点的训练集\n",
    "        data_indexes = curr_node.data_indexes\n",
    "\n",
    "        # 判断当前节点样本集是否小于预定值\n",
    "        if len(data_indexes) <= self.min_samples_leaf:\n",
    "            curr_node.leaf_type = parent_mean_score\n",
    "            return\n",
    "\n",
    "        node_data_set = self.split_data(data_indexes)\n",
    "        # 得到当前训练集样本对应的类别\n",
    "        node_data_set_targets = []\n",
    "        for item in node_data_set:\n",
    "            node_data_set_targets.append(item['target'])\n",
    "\n",
    "        # 得到当前节点样本集的样本平均分\n",
    "        mean_score = sum(node_data_set_targets) / len(node_data_set_targets)\n",
    "        if deepth >= self.max_deepth:\n",
    "            curr_node.leaf_type = mean_score\n",
    "            return\n",
    "\n",
    "        # 判断待划分属性是否为空or样本属性值都一样（类别可能不一样）\n",
    "        remain_attrs = copy.deepcopy(curr_node.remain_attrs) # 得到当前节点的剩余待划分属性\n",
    "        # print(remain_attrs)\n",
    "        # 判断待划分属性是否为空\n",
    "        empty_flag = 0\n",
    "        if len(remain_attrs) <= 1:\n",
    "            empty_flag = 1\n",
    "        # 判断样本属性值是否都一样\n",
    "        temp_node_data_set = copy.deepcopy(node_data_set) # 先复制一份数据\n",
    "        for item in temp_node_data_set:\n",
    "            del item['target'] # 因为类别可能不一样，就先删除类别的键值对\n",
    "        temp_item = temp_node_data_set[0] # 便于比较\n",
    "        same_flag = 1\n",
    "        for item in temp_node_data_set:\n",
    "            if item != temp_item: # 只要有一个不同，数据集中的样本就不一样\n",
    "                same_flag = 0\n",
    "        # 是则标记当前节点为样本平均分（叶节点）\n",
    "        if empty_flag or same_flag:\n",
    "            curr_node.leaf_type = mean_score\n",
    "            return\n",
    "\n",
    "        # 选择最优划分属性\n",
    "        selected_attr, split_value = self.get_best_divide_attr_reg(curr_node)\n",
    "        # 从剩余属性列表中移除被选择的属性\n",
    "        if selected_attr in self.discrete_attrs:\n",
    "            # 从剩余属性列表中移除被选择的属性\n",
    "            remain_attrs.remove(selected_attr)\n",
    "        # print(selected_attr)\n",
    "        # 填充{划分属性:划分属性值}\n",
    "        curr_node.attr_name2split_value[selected_attr] = split_value\n",
    "\n",
    "        # 为选择的属性生成左孩子和右孩子\n",
    "        # filter函数得到比划分值小、比划分值大的两部分数据集\n",
    "        left_data_set_indexes = list(filter(lambda index: self.data_set[index][selected_attr] <= curr_node.attr_name2split_value[selected_attr], data_indexes))\n",
    "        right_data_set_indexes = list(filter(lambda index: self.data_set[index][selected_attr] > curr_node.attr_name2split_value[selected_attr], data_indexes))\n",
    "        # 左右孩子所划到的样本的属性值，左孩子的属性值为'<=划分值'\n",
    "        left_attr_value = '<=' + str(curr_node.attr_name2split_value[selected_attr])\n",
    "        right_attr_value = '>' + str(curr_node.attr_name2split_value[selected_attr])\n",
    "        curr_node.left_child = Node(attr_value=left_attr_value, parent=curr_node, remain_attrs=remain_attrs, data_indexes=left_data_set_indexes)\n",
    "        curr_node.right_child = Node(attr_value=right_attr_value, parent=curr_node, remain_attrs=remain_attrs, data_indexes=right_data_set_indexes)\n",
    "\n",
    "        # 递归构建左右子树，同时深度+1，并且传参当前节点样本的均值进入子节点的递归\n",
    "        self.build_regression_tree(curr_node.left_child, mean_score, deepth+1)\n",
    "        self.build_regression_tree(curr_node.right_child, mean_score, deepth+1)\n",
    "\n",
    "\n",
    "    def grow_regression_CART(self):\n",
    "        \"\"\"\n",
    "        生成一颗回归树\n",
    "        \n",
    "        return: 最终得到一颗回归树，可以沿着根节点走完整棵树\n",
    "        \"\"\"\n",
    "        root_data_indexes = []\n",
    "        for i in range(len(self.data_set)):\n",
    "            root_data_indexes.append(i)\n",
    "        root_node = Node(remain_attrs=copy.deepcopy(self.attr_names), data_indexes=root_data_indexes)\n",
    "        self.root = root_node\n",
    "        self.build_regression_tree(root_node, parent_mean_score=0, deepth=1)\n",
    "\n",
    "\n",
    "    def post_pruning(self, test_dict_list):\n",
    "        \"\"\"\n",
    "        生成一棵树之后进行后剪枝，且以尽量精简树的结构为目标\n",
    "        \n",
    "        param test_dict_list: 测试集\n",
    "        return: 得到一个剪枝后的树的根节点\n",
    "        \"\"\"\n",
    "        print('剪枝中...')\n",
    "        nodes_waiting_judge = [] # 待剪枝节点列表\n",
    "        node_queue = [] # 节点队列\n",
    "        node_queue.append(self.root)\n",
    "        # 首先使用广度优先遍历将最后一层分支节点加入待剪枝列表\n",
    "        while len(node_queue) > 0:\n",
    "            curr_node = node_queue[0]\n",
    "            # 首先判断是分支节点\n",
    "            if curr_node.leaf_type is None:\n",
    "                node_queue.append(curr_node.left_child)\n",
    "                node_queue.append(curr_node.right_child)\n",
    "                # 其次判断左右孩子都是叶节点\n",
    "                if curr_node.left_child.leaf_type and curr_node.right_child.leaf_type:\n",
    "                    nodes_waiting_judge.append(curr_node)\n",
    "            node_queue.remove(curr_node)\n",
    "        # 进行剪枝\n",
    "        while len(nodes_waiting_judge) > 0:\n",
    "            curr_node = nodes_waiting_judge.pop() # 获取当前节点，同时从列表中pop出去\n",
    "            # 得到剪枝前的准确率orR2值\n",
    "            if self.tree_type:\n",
    "                acc_before_prune = self.test_classify(test_dict_list)\n",
    "            else:\n",
    "                acc_before_prune = self.test_reg_R2(test_dict_list)\n",
    "            node_data_set = self.split_data(curr_node.data_indexes)\n",
    "            # 得到当前训练集样本对应的类别\n",
    "            node_data_set_targets = []\n",
    "            for item in node_data_set:\n",
    "                node_data_set_targets.append(item['target'])\n",
    "            # 得到剪枝后的准确率orR2值\n",
    "            if self.tree_type:\n",
    "                leaf_type = max(node_data_set_targets, key=node_data_set_targets.count)\n",
    "                curr_node.leaf_type = leaf_type # 这里注意，在test函数中判断是否到达叶子节点使用leaf_type而不是attr_name2split_value\n",
    "                acc_after_prune = self.test_classify(test_dict_list)\n",
    "            else:\n",
    "                mean_score = sum(node_data_set_targets) / len(node_data_set_targets)\n",
    "                curr_node.leaf_type = mean_score\n",
    "                acc_after_prune = self.test_reg_R2(test_dict_list)\n",
    "            # 判断是否剪枝\n",
    "            if acc_before_prune > acc_after_prune: # 不剪枝\n",
    "                curr_node.leaf_type = None # 回退leaf_type值\n",
    "            else: # 剪枝\n",
    "                curr_node.attr_name2split_value = {} # 保持叶子节点的属性同步\n",
    "                curr_node.left_child = None\n",
    "                curr_node.right_child = None\n",
    "                # 判断父节点是否也要加入待剪枝列表\n",
    "                parent_node = curr_node.parent\n",
    "                if parent_node.left_child.leaf_type and parent_node.right_child.leaf_type:\n",
    "                    nodes_waiting_judge.append(parent_node)\n",
    "\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        打印这棵树以便直观的观察分类规则\n",
    "        \"\"\"\n",
    "        # 使用队列，以广度优先的方法打印每一层的节点\n",
    "        node_queue = [copy.deepcopy(self.root)]\n",
    "        node_cnt = 1\n",
    "        while(len(node_queue)>0):\n",
    "            node_cnt += 1\n",
    "            curr_node = node_queue[0]\n",
    "            # print(curr_node.node_to_string()) # 调用Node的描述方法\n",
    "            # 不能用if not curr_node.leaf_type: 因为0也是其中一个类型，这样会把叶子节点误判为分支节点\n",
    "            if curr_node.leaf_type is None:\n",
    "                node_queue.append(curr_node.left_child)\n",
    "                node_queue.append(curr_node.right_child)\n",
    "            node_queue.remove(curr_node)\n",
    "            # print('---------------------------------------')\n",
    "        print('节点总数为：', node_cnt)\n",
    "\n",
    "\n",
    "    def test_classify(self, test_dict_list):\n",
    "        \"\"\"\n",
    "        对输入的测试集调用决策树进行预测分类\n",
    "        \n",
    "        param test_dict_list: 测试集，和训练集一样是字典列表\n",
    "        return acc: 准确率\n",
    "        \"\"\"\n",
    "        target = []\n",
    "        pre_target = []\n",
    "        cnt = 0\n",
    "        for item in test_dict_list:\n",
    "            curr_node = copy.deepcopy(self.root)\n",
    "            while curr_node.leaf_type is None:\n",
    "                if item[list(curr_node.attr_name2split_value.keys())[0]] <= list(curr_node.attr_name2split_value.values())[0]:\n",
    "                    curr_node = curr_node.left_child\n",
    "                else:\n",
    "                    curr_node = curr_node.right_child\n",
    "            if item['target'] == curr_node.leaf_type:\n",
    "                cnt += 1\n",
    "            target.append(item['target'])\n",
    "            pre_target.append(curr_node.leaf_type)\n",
    "        acc = cnt / len(test_dict_list)\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def test_reg_R2(self, test_dict_list):\n",
    "        \"\"\"\n",
    "        对输入的测试集调用决策树进行预测回归\n",
    "        \n",
    "        param test_dict_list: 测试集，和训练集一样是字典列表\n",
    "        return R2: R2值，越大越好，最大为1\n",
    "        \"\"\"\n",
    "        target = []\n",
    "        pre_target = []\n",
    "        for item in test_dict_list:\n",
    "            curr_node = copy.deepcopy(self.root)\n",
    "            while curr_node.leaf_type is None:\n",
    "                if item[list(curr_node.attr_name2split_value.keys())[0]] <= list(curr_node.attr_name2split_value.values())[0]:\n",
    "                    curr_node = curr_node.left_child\n",
    "                else:\n",
    "                    curr_node = curr_node.right_child\n",
    "            target.append(item['target'])\n",
    "            pre_target.append(curr_node.leaf_type)\n",
    "        #mse = mean_squared_error(target, pre_target)\n",
    "        #R2=1-mse/np.var(target)\n",
    "        R2=r2_score(target,pre_target)\n",
    "        # print('R2=', R2)\n",
    "        return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ee7c7c-e275-4732-980e-fc99dc70f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data, attributes):\n",
    "    \"\"\"\n",
    "    构造字典数据集\n",
    "    param data: 二维列表，存储每一行数据\n",
    "    param attributes: 属性种类列表\n",
    "    return: 一个字典列表，每一行数据以字典的方式将属性和值对应起来\n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    for item in data:\n",
    "        item_dict = {}\n",
    "        for i in range(len(attributes)):\n",
    "            item_dict[attributes[i]] = item[i]\n",
    "        dict_list.append(item_dict)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8155cd-a95f-4724-a4f4-05bc003e7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(node, s='root'):\n",
    "    \"\"\"\n",
    "    工具类，用于深度优先打印一棵树，检查树的生成是否有问题\n",
    "    例如叶子节点的划分属性和类别同时为空，就有问题\n",
    "    \n",
    "    param node: 节点\n",
    "    param s: 用于打印路径，默认在root\n",
    "    \"\"\"\n",
    "    if node == None:\n",
    "        return\n",
    "    print('划分：', node.attr_name2split_value, '\\t属性：', node.leaf_type, '\\t属性值：', node.attr_value)\n",
    "    if node.attr_name2split_value == {} and node.leaf_type != None:\n",
    "        s += '：叶子'\n",
    "        print('一条路径完毕')\n",
    "    if node.attr_name2split_value == {} and node.leaf_type == None:\n",
    "        print('【叶节点生成错误】叶节点的划分属性与叶子类型不可同时为空！')\n",
    "    print(s, '\\n----------------------------------------')\n",
    "    DFS(node.left_child, s+'->left')\n",
    "    DFS(node.right_child, s+'->right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ab6d5ef-c74c-4b30-8c55-9b9defce8877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在测试鸢尾花三分类任务...\n",
      "节点总数为： 22\n",
      "训练集准确率= 1.0\n",
      "测试集准确率= 0.9\n",
      "剪枝中...\n",
      "******************************剪枝后******************************\n",
      "节点总数为： 14\n",
      "训练集准确率= 0.9416666666666667\n",
      "测试集准确率= 0.9666666666666667\n",
      "划分： {'petal_length': 1.4} \t属性： None \t属性值： None\n",
      "root \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 0 \t属性值： <=1.4\n",
      "一条路径完毕\n",
      "root->left：叶子 \n",
      "----------------------------------------\n",
      "划分： {'petal_width': 0.25} \t属性： None \t属性值： >1.4\n",
      "root->right \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 0 \t属性值： <=0.25\n",
      "一条路径完毕\n",
      "root->right->left：叶子 \n",
      "----------------------------------------\n",
      "划分： {'petal_width': 1.1} \t属性： None \t属性值： >0.25\n",
      "root->right->right \n",
      "----------------------------------------\n",
      "划分： {'sepal_width': 2.95} \t属性： None \t属性值： <=1.1\n",
      "root->right->right->left \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 1 \t属性值： <=2.95\n",
      "一条路径完毕\n",
      "root->right->right->left->left：叶子 \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 0 \t属性值： >2.95\n",
      "一条路径完毕\n",
      "root->right->right->left->right：叶子 \n",
      "----------------------------------------\n",
      "划分： {'petal_width': 1.3} \t属性： None \t属性值： >1.1\n",
      "root->right->right->right \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 1 \t属性值： <=1.3\n",
      "一条路径完毕\n",
      "root->right->right->right->left：叶子 \n",
      "----------------------------------------\n",
      "划分： {'petal_width': 1.5} \t属性： None \t属性值： >1.3\n",
      "root->right->right->right->right \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 1 \t属性值： <=1.5\n",
      "一条路径完毕\n",
      "root->right->right->right->right->left：叶子 \n",
      "----------------------------------------\n",
      "划分： {} \t属性： 2 \t属性值： >1.5\n",
      "一条路径完毕\n",
      "root->right->right->right->right->right：叶子 \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def classify_iris_test():\n",
    "    \"\"\"\n",
    "    测试决策树在鸢尾花数据集的准确度\n",
    "    \"\"\"\n",
    "    def load_iris_data():\n",
    "        \"\"\"\n",
    "        加载鸢尾花数据集\n",
    "        return: 训练字典列表与对应的类别，测试字典列表与对应的类别\n",
    "        \"\"\"\n",
    "        iris = load_iris()\n",
    "        # 以3:1划分训练集与测试集\n",
    "        train_data, test_data, train_target, test_target = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "        train_data = train_data.tolist()\n",
    "        test_data = test_data.tolist()\n",
    "        for i in range(len(train_data)):\n",
    "            train_data[i].append(train_target[i])\n",
    "        for i in range(len(test_data)):\n",
    "            test_data[i].append(test_target[i])\n",
    "        attributes = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target']\n",
    "\n",
    "        #将特征和数据连接起来\n",
    "        train_dict_list = load(train_data, attributes)\n",
    "\n",
    "        test_dict_list = load(test_data, attributes)\n",
    "        return train_dict_list, test_dict_list\n",
    "    print('正在测试鸢尾花三分类任务...')\n",
    "    # 得到训练集和测试集\n",
    "    train_dict_list, test_dict_list = load_iris_data()\n",
    "    # 训练分类树\n",
    "    cart = CART(train_dict_list)\n",
    "    # 层层打印这棵树\n",
    "    cart.print_tree()\n",
    "    # 输入测试集进行测试\n",
    "    acc_before_prune = cart.test_classify(test_dict_list)\n",
    "    acc1=cart.test_classify(train_dict_list)\n",
    "    print('训练集准确率=', acc1)\n",
    "    print('测试集准确率=', acc_before_prune)\n",
    "    #剪枝操作\n",
    "    cart.post_pruning(test_dict_list)\n",
    "    print('******************************剪枝后******************************')\n",
    "    cart.print_tree()\n",
    "    acc2=cart.test_classify(train_dict_list)\n",
    "    acc_after_prune = cart.test_classify(test_dict_list)\n",
    "    print('训练集准确率=', acc2)\n",
    "    print('测试集准确率=', acc_after_prune)\n",
    "    DFS(cart.root, 'root')\n",
    "classify_iris_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57507e41-d024-4381-b0d6-91285031c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在测试红酒三分类任务...\n",
      "节点总数为： 28\n",
      "训练集准确率= 1.0\n",
      "测试集准确率= 0.9444444444444444\n",
      "剪枝中...\n",
      "******************************剪枝后******************************\n",
      "节点总数为： 22\n",
      "训练集准确率= 0.9225352112676056\n",
      "测试集准确率= 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "def classify_wine_test():\n",
    "    \"\"\"\n",
    "    测试决策树在红酒数据集的准确度\n",
    "    \"\"\"\n",
    "    def load_wine_data():\n",
    "        \"\"\"\n",
    "        加载红酒数据集\n",
    "        return: 训练字典列表与对应的类别，测试字典列表与对应的类别\n",
    "        \"\"\"\n",
    "        wine = load_wine()\n",
    "        # 以3:1划分训练集与测试集\n",
    "        train_data, test_data, train_target, test_target = train_test_split(wine.data, wine.target, test_size=0.2)\n",
    "        train_data = train_data.tolist()\n",
    "        test_data = test_data.tolist()\n",
    "        for i in range(len(train_data)):\n",
    "            train_data[i].append(train_target[i])\n",
    "        for i in range(len(test_data)):\n",
    "            test_data[i].append(test_target[i])\n",
    "\n",
    "        attributes = ['酒精', '苹果酸', '灰', '灰的碱性', '镁', '总酚', '类黄酮', '非黄烷类酚类', '花青素', '颜色强度',\n",
    "                      '色调', '稀释葡萄酒', '脯氨酸', 'target']\n",
    "        train_dict_list = load(train_data, attributes)\n",
    "        test_dict_list = load(test_data, attributes)\n",
    "        return train_dict_list, test_dict_list\n",
    "    print('正在测试红酒三分类任务...')\n",
    "    # 得到训练集和测试集\n",
    "    train_dict_list, test_dict_list = load_wine_data()\n",
    "    # 训练分类树\n",
    "    cart = CART(train_dict_list)\n",
    "    # 层层打印这棵树\n",
    "    cart.print_tree()\n",
    "    # 输入测试集进行测试\n",
    "    acc_before_prune = cart.test_classify(test_dict_list)\n",
    "    acc1=cart.test_classify(train_dict_list)\n",
    "    print('训练集准确率=', acc1)\n",
    "    print('测试集准确率=', acc_before_prune)\n",
    "    #剪枝操作\n",
    "    cart.post_pruning(test_dict_list)\n",
    "    print('******************************剪枝后******************************')\n",
    "    cart.print_tree()\n",
    "    acc2=cart.test_classify(train_dict_list)\n",
    "    acc_after_prune = cart.test_classify(test_dict_list)\n",
    "    print('训练集准确率=', acc2)\n",
    "    print('测试集准确率=', acc_after_prune)\n",
    "classify_wine_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910c2d7d-b74e-4cb6-bfb6-0752fd32991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在测试波士顿房价回归任务...\n",
      "节点总数为： 144\n",
      "R2= 0.5675072831341761\n",
      "剪枝中...\n",
      "******************************剪枝后******************************\n",
      "节点总数为： 76\n",
      "R2= 0.6443924393133812\n"
     ]
    }
   ],
   "source": [
    "def regression_boston_test():\n",
    "    \"\"\"\n",
    "    测试决策树在波士顿房价数据集的准确度\n",
    "    \"\"\"\n",
    "    def load_boston_data():\n",
    "        \"\"\"\n",
    "        加载波士顿房价数据集\n",
    "        \n",
    "        return: 训练字典列表与对应的类别，测试字典列表与对应的类别\n",
    "        \"\"\"\n",
    "        boston = load_boston()\n",
    "        # 以3:1划分训练集与测试集\n",
    "        train_data, test_data, train_target, test_target = train_test_split(boston.data, boston.target, test_size=0.2)\n",
    "        train_data = train_data.tolist()\n",
    "        test_data = test_data.tolist()\n",
    "        for i in range(len(train_data)):\n",
    "            train_data[i].append(train_target[i])\n",
    "        for i in range(len(test_data)):\n",
    "            test_data[i].append(test_target[i])\n",
    "\n",
    "        attributes = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'target',]\n",
    "        train_dict_list = load(train_data, attributes)\n",
    "        test_dict_list = load(test_data, attributes)\n",
    "        return train_dict_list, test_dict_list\n",
    "\n",
    "    print('正在测试波士顿房价回归任务...')\n",
    "    # 得到训练集和测试集\n",
    "    train_dict_list, test_dict_list = load_boston_data()\n",
    "    # 训练分类树\n",
    "    cart = CART(train_dict_list, tree_type=0)\n",
    "    # 层层打印这棵树\n",
    "    cart.print_tree()\n",
    "    cart.test_reg_R2(test_dict_list)\n",
    "    # 输入测试集进行测试\n",
    "    acc_before_prune = cart.test_reg_R2(test_dict_list)\n",
    "    print('R2=', acc_before_prune)\n",
    "    cart.post_pruning(test_dict_list)\n",
    "    print('******************************剪枝后******************************')\n",
    "    cart.print_tree()\n",
    "    acc_after_prune = cart.test_reg_R2(test_dict_list)\n",
    "    print('R2=', acc_after_prune)\n",
    "    # DFS(cart.root, 'root')\n",
    "regression_boston_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5595c880-99cb-477c-ba6f-6e9e0bf9d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在测试糖尿病回归任务...\n",
      "节点总数为： 100\n",
      "R2= 0.3821136230718515\n",
      "剪枝中...\n",
      "******************************剪枝后******************************\n",
      "节点总数为： 54\n",
      "R2= 0.4058557714808688\n"
     ]
    }
   ],
   "source": [
    "def regression_diabetes_test():\n",
    "    \"\"\"\n",
    "    测试决策树在糖尿病数据集的准确度\n",
    "    \"\"\"\n",
    "    def load_diabetes_data():\n",
    "        \"\"\"\n",
    "        加载糖尿病数据集\n",
    "        \n",
    "        return: 训练字典列表与对应的类别，测试字典列表与对应的类别\n",
    "        \"\"\"\n",
    "        diabetes = load_diabetes()\n",
    "        # 以3:1划分训练集与测试集\n",
    "        train_data, test_data, train_target, test_target = train_test_split(diabetes.data, diabetes.target, test_size=0.2)\n",
    "        train_data = train_data.tolist()\n",
    "        test_data = test_data.tolist()\n",
    "        for i in range(len(train_data)):\n",
    "            train_data[i].append(train_target[i])\n",
    "        for i in range(len(test_data)):\n",
    "            test_data[i].append(test_target[i])\n",
    "\n",
    "        attributes = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target',]\n",
    "        train_dict_list = load(train_data, attributes)\n",
    "        test_dict_list = load(test_data, attributes)\n",
    "        return train_dict_list, test_dict_list\n",
    "\n",
    "    print('正在测试糖尿病回归任务...')\n",
    "    # 得到训练集和测试集\n",
    "    train_dict_list, test_dict_list = load_diabetes_data()\n",
    "    # 训练分类树\n",
    "    cart = CART(train_dict_list, tree_type=0)\n",
    "    # 层层打印这棵树\n",
    "    cart.print_tree()\n",
    "    cart.test_reg_R2(test_dict_list)\n",
    "    # 输入测试集进行测试\n",
    "    acc_before_prune = cart.test_reg_R2(test_dict_list)\n",
    "    print('R2=', acc_before_prune)\n",
    "    cart.post_pruning(test_dict_list)\n",
    "    print('******************************剪枝后******************************')\n",
    "    cart.print_tree()\n",
    "    acc_after_prune = cart.test_reg_R2(test_dict_list)\n",
    "    print('R2=', acc_after_prune)\n",
    "regression_diabetes_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
